{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business have targets to achieve. We can project sales to predict the business's performance' in future time. It is useful to zoom out and look at the broader picture as well. By considering all our efforts on the customer side, how do we affect the sales?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/tridoan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/tridoan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/tridoan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/tridoan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/tridoan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/tridoan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from datetime import datetime, timedelta,date\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given 5 years of store-item sales data, and asked to predict 3 months of sales for 50 different items at 10 different stores.\n",
    "\n",
    "What's the best way to deal with seasonality? Should stores be modeled separately, or can you pool them together? Does deep learning work better than ARIMA? Can either beat xgboost?[data](https://www.kaggle.com/c/demand-forecasting-kernels-only/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales = pd.read_csv('./Downloads/data/sale_data.csv')\n",
    "df_sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  store  item  sales\n",
       "0  2013-01-01      1     1     13\n",
       "1  2013-01-02      1     1     11\n",
       "2  2013-01-03      1     1     14\n",
       "3  2013-01-04      1     1     13\n",
       "4  2013-01-05      1     1     10\n",
       "5  2013-01-06      1     1     12\n",
       "6  2013-01-07      1     1     10\n",
       "7  2013-01-08      1     1      9\n",
       "8  2013-01-09      1     1     12\n",
       "9  2013-01-10      1     1      9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store  item  sales\n",
       "0 2013-01-01      1     1     13\n",
       "1 2013-01-01      1     1     11\n",
       "2 2013-01-01      1     1     14\n",
       "3 2013-01-01      1     1     13\n",
       "4 2013-01-01      1     1     10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales['date'] = pd.to_datetime(df_sales['date'])\n",
    "\n",
    "#represent month in date field as its first day\n",
    "df_sales['date'] = df_sales['date'].dt.year.astype('str') + '-' + df_sales['date'].dt.month.astype('str') + '-01'\n",
    "df_sales['date'] = pd.to_datetime(df_sales['date'])\n",
    "\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to forecast monthly total sales. We need to aggregate our data at the monthly level and sum up the sales column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>454904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>459417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>617382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>682274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>763242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   sales\n",
       "0 2013-01-01  454904\n",
       "1 2013-02-01  459417\n",
       "2 2013-03-01  617382\n",
       "3 2013-04-01  682274\n",
       "4 2013-05-01  763242"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groupby date and sum the sales\n",
    "df_sales = df_sales.groupby('date').sales.sum().reset_index()\n",
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first deal to work on non-stationary  and trending issue. One method is to get the difference in sales compared to the previous month and build the model on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>prev_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>454904</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>459417</td>\n",
       "      <td>454904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>617382</td>\n",
       "      <td>459417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>682274</td>\n",
       "      <td>617382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>763242</td>\n",
       "      <td>682274.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   sales  prev_sales\n",
       "0 2013-01-01  454904         NaN\n",
       "1 2013-02-01  459417    454904.0\n",
       "2 2013-03-01  617382    459417.0\n",
       "3 2013-04-01  682274    617382.0\n",
       "4 2013-05-01  763242    682274.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new dataframe to model the difference\n",
    "df_diff = df_sales.copy()\n",
    "\n",
    "#add previous sales to the next row\n",
    "df_diff['prev_sales'] = df_diff['sales'].shift(1)   \n",
    "\n",
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>prev_sales</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>459417</td>\n",
       "      <td>454904.0</td>\n",
       "      <td>4513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>617382</td>\n",
       "      <td>459417.0</td>\n",
       "      <td>157965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>682274</td>\n",
       "      <td>617382.0</td>\n",
       "      <td>64892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>763242</td>\n",
       "      <td>682274.0</td>\n",
       "      <td>80968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>795597</td>\n",
       "      <td>763242.0</td>\n",
       "      <td>32355.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   sales  prev_sales      diff\n",
       "1 2013-02-01  459417    454904.0    4513.0\n",
       "2 2013-03-01  617382    459417.0  157965.0\n",
       "3 2013-04-01  682274    617382.0   64892.0\n",
       "4 2013-05-01  763242    682274.0   80968.0\n",
       "5 2013-06-01  795597    763242.0   32355.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the null values and calculate the difference\n",
    "df_diff = df_diff.dropna()\n",
    "\n",
    "df_diff['diff'] = (df_diff['sales'] - df_diff['prev_sales'])\n",
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use previous monthly sales data to forecast the next ones. The look-back period may vary for every model. Ours will be 12 for this example.\n",
    "So what we need to do is to create columns from lag_1 to lag_12 and assign values by using shift() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>diff</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>lag_10</th>\n",
       "      <th>lag_11</th>\n",
       "      <th>lag_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>459417</td>\n",
       "      <td>4513.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>617382</td>\n",
       "      <td>157965.0</td>\n",
       "      <td>4513.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>682274</td>\n",
       "      <td>64892.0</td>\n",
       "      <td>157965.0</td>\n",
       "      <td>4513.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>763242</td>\n",
       "      <td>80968.0</td>\n",
       "      <td>64892.0</td>\n",
       "      <td>157965.0</td>\n",
       "      <td>4513.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>795597</td>\n",
       "      <td>32355.0</td>\n",
       "      <td>80968.0</td>\n",
       "      <td>64892.0</td>\n",
       "      <td>157965.0</td>\n",
       "      <td>4513.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   sales      diff     lag_1     lag_2     lag_3   lag_4  lag_5  \\\n",
       "1 2013-02-01  459417    4513.0       NaN       NaN       NaN     NaN    NaN   \n",
       "2 2013-03-01  617382  157965.0    4513.0       NaN       NaN     NaN    NaN   \n",
       "3 2013-04-01  682274   64892.0  157965.0    4513.0       NaN     NaN    NaN   \n",
       "4 2013-05-01  763242   80968.0   64892.0  157965.0    4513.0     NaN    NaN   \n",
       "5 2013-06-01  795597   32355.0   80968.0   64892.0  157965.0  4513.0    NaN   \n",
       "\n",
       "   lag_6  lag_7  lag_8  lag_9  lag_10  lag_11  lag_12  \n",
       "1    NaN    NaN    NaN    NaN     NaN     NaN     NaN  \n",
       "2    NaN    NaN    NaN    NaN     NaN     NaN     NaN  \n",
       "3    NaN    NaN    NaN    NaN     NaN     NaN     NaN  \n",
       "4    NaN    NaN    NaN    NaN     NaN     NaN     NaN  \n",
       "5    NaN    NaN    NaN    NaN     NaN     NaN     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new dataframe from transformation from time series to supervised\n",
    "df_supervised = df_diff.drop(['prev_sales'],axis=1)\n",
    "\n",
    "#adding lags\n",
    "for inc in range(1,13):\n",
    "    field_name = 'lag_' + str(inc)\n",
    "    df_supervised[field_name] = df_supervised['diff'].shift(inc)\n",
    "\n",
    "df_supervised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>diff</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>lag_10</th>\n",
       "      <th>lag_11</th>\n",
       "      <th>lag_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>1171393</td>\n",
       "      <td>106769.0</td>\n",
       "      <td>43938.0</td>\n",
       "      <td>81824.0</td>\n",
       "      <td>116195.0</td>\n",
       "      <td>201298.0</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>-46105.0</td>\n",
       "      <td>-228037.0</td>\n",
       "      <td>27811.0</td>\n",
       "      <td>-33194.0</td>\n",
       "      <td>-84663.0</td>\n",
       "      <td>-157224.0</td>\n",
       "      <td>116054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1026403</td>\n",
       "      <td>-144990.0</td>\n",
       "      <td>106769.0</td>\n",
       "      <td>43938.0</td>\n",
       "      <td>81824.0</td>\n",
       "      <td>116195.0</td>\n",
       "      <td>201298.0</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>-46105.0</td>\n",
       "      <td>-228037.0</td>\n",
       "      <td>27811.0</td>\n",
       "      <td>-33194.0</td>\n",
       "      <td>-84663.0</td>\n",
       "      <td>-157224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>935263</td>\n",
       "      <td>-91140.0</td>\n",
       "      <td>-144990.0</td>\n",
       "      <td>106769.0</td>\n",
       "      <td>43938.0</td>\n",
       "      <td>81824.0</td>\n",
       "      <td>116195.0</td>\n",
       "      <td>201298.0</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>-46105.0</td>\n",
       "      <td>-228037.0</td>\n",
       "      <td>27811.0</td>\n",
       "      <td>-33194.0</td>\n",
       "      <td>-84663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>891160</td>\n",
       "      <td>-44103.0</td>\n",
       "      <td>-91140.0</td>\n",
       "      <td>-144990.0</td>\n",
       "      <td>106769.0</td>\n",
       "      <td>43938.0</td>\n",
       "      <td>81824.0</td>\n",
       "      <td>116195.0</td>\n",
       "      <td>201298.0</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>-46105.0</td>\n",
       "      <td>-228037.0</td>\n",
       "      <td>27811.0</td>\n",
       "      <td>-33194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>928837</td>\n",
       "      <td>37677.0</td>\n",
       "      <td>-44103.0</td>\n",
       "      <td>-91140.0</td>\n",
       "      <td>-144990.0</td>\n",
       "      <td>106769.0</td>\n",
       "      <td>43938.0</td>\n",
       "      <td>81824.0</td>\n",
       "      <td>116195.0</td>\n",
       "      <td>201298.0</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>-46105.0</td>\n",
       "      <td>-228037.0</td>\n",
       "      <td>27811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>695170</td>\n",
       "      <td>-233667.0</td>\n",
       "      <td>37677.0</td>\n",
       "      <td>-44103.0</td>\n",
       "      <td>-91140.0</td>\n",
       "      <td>-144990.0</td>\n",
       "      <td>106769.0</td>\n",
       "      <td>43938.0</td>\n",
       "      <td>81824.0</td>\n",
       "      <td>116195.0</td>\n",
       "      <td>201298.0</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>-46105.0</td>\n",
       "      <td>-228037.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    sales      diff     lag_1     lag_2     lag_3     lag_4  \\\n",
       "54 2017-07-01  1171393  106769.0   43938.0   81824.0  116195.0  201298.0   \n",
       "55 2017-08-01  1026403 -144990.0  106769.0   43938.0   81824.0  116195.0   \n",
       "56 2017-09-01   935263  -91140.0 -144990.0  106769.0   43938.0   81824.0   \n",
       "57 2017-10-01   891160  -44103.0  -91140.0 -144990.0  106769.0   43938.0   \n",
       "58 2017-11-01   928837   37677.0  -44103.0  -91140.0 -144990.0  106769.0   \n",
       "59 2017-12-01   695170 -233667.0   37677.0  -44103.0  -91140.0 -144990.0   \n",
       "\n",
       "       lag_5     lag_6     lag_7     lag_8     lag_9    lag_10    lag_11  \\\n",
       "54    4063.0  -46105.0 -228037.0   27811.0  -33194.0  -84663.0 -157224.0   \n",
       "55  201298.0    4063.0  -46105.0 -228037.0   27811.0  -33194.0  -84663.0   \n",
       "56  116195.0  201298.0    4063.0  -46105.0 -228037.0   27811.0  -33194.0   \n",
       "57   81824.0  116195.0  201298.0    4063.0  -46105.0 -228037.0   27811.0   \n",
       "58   43938.0   81824.0  116195.0  201298.0    4063.0  -46105.0 -228037.0   \n",
       "59  106769.0   43938.0   81824.0  116195.0  201298.0    4063.0  -46105.0   \n",
       "\n",
       "      lag_12  \n",
       "54  116054.0  \n",
       "55 -157224.0  \n",
       "56  -84663.0  \n",
       "57  -33194.0  \n",
       "58   27811.0  \n",
       "59 -228037.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supervised.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "df_supervised = df_supervised.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How useful are our features for prediction?**\n",
    "Adjusted R-squared is the answer. It tells us how good our features explain the variation in our label (lag_1 to lag_12 for diff, in our example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02893426930900389\n"
     ]
    }
   ],
   "source": [
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "# Define the regression formula\n",
    "model = smf.ols(formula='diff ~ lag_1', data=df_supervised)\n",
    "\n",
    "# Fit the regression\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = model_fit.rsquared_adj\n",
    "print(regression_adj_rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we fit a linear regression model (OLS — Ordinary Least Squares) and calculate the Adjusted R-squared. For the example above, we just used lag_1 to see how much it explains the variation in column diff. lag_1 explains 3% of the variation.     \n",
    "\n",
    "Let add more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4406493613886947\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the regression formula\n",
    "model = smf.ols(formula='diff ~ lag_1 + lag_2 + lag_3 + lag_4 + lag_5', data=df_supervised)\n",
    "\n",
    "# Fit the regression\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = model_fit.rsquared_adj\n",
    "print(regression_adj_rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding four more features increased the score from 3% to 44%**. Let use full features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>diff</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>lag_10</th>\n",
       "      <th>lag_11</th>\n",
       "      <th>lag_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>19380.0</td>\n",
       "      <td>-186036.0</td>\n",
       "      <td>36056.0</td>\n",
       "      <td>-33320.0</td>\n",
       "      <td>-76854.0</td>\n",
       "      <td>-89161.0</td>\n",
       "      <td>60325.0</td>\n",
       "      <td>32355.0</td>\n",
       "      <td>80968.0</td>\n",
       "      <td>64892.0</td>\n",
       "      <td>157965.0</td>\n",
       "      <td>4513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>175184.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>19380.0</td>\n",
       "      <td>-186036.0</td>\n",
       "      <td>36056.0</td>\n",
       "      <td>-33320.0</td>\n",
       "      <td>-76854.0</td>\n",
       "      <td>-89161.0</td>\n",
       "      <td>60325.0</td>\n",
       "      <td>32355.0</td>\n",
       "      <td>80968.0</td>\n",
       "      <td>64892.0</td>\n",
       "      <td>157965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>84613.0</td>\n",
       "      <td>175184.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>19380.0</td>\n",
       "      <td>-186036.0</td>\n",
       "      <td>36056.0</td>\n",
       "      <td>-33320.0</td>\n",
       "      <td>-76854.0</td>\n",
       "      <td>-89161.0</td>\n",
       "      <td>60325.0</td>\n",
       "      <td>32355.0</td>\n",
       "      <td>80968.0</td>\n",
       "      <td>64892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>93963.0</td>\n",
       "      <td>84613.0</td>\n",
       "      <td>175184.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>19380.0</td>\n",
       "      <td>-186036.0</td>\n",
       "      <td>36056.0</td>\n",
       "      <td>-33320.0</td>\n",
       "      <td>-76854.0</td>\n",
       "      <td>-89161.0</td>\n",
       "      <td>60325.0</td>\n",
       "      <td>32355.0</td>\n",
       "      <td>80968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>23965.0</td>\n",
       "      <td>93963.0</td>\n",
       "      <td>84613.0</td>\n",
       "      <td>175184.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>19380.0</td>\n",
       "      <td>-186036.0</td>\n",
       "      <td>36056.0</td>\n",
       "      <td>-33320.0</td>\n",
       "      <td>-76854.0</td>\n",
       "      <td>-89161.0</td>\n",
       "      <td>60325.0</td>\n",
       "      <td>32355.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      diff     lag_1     lag_2     lag_3     lag_4     lag_5  \\\n",
       "0 2014-02-01    3130.0   19380.0 -186036.0   36056.0  -33320.0  -76854.0   \n",
       "1 2014-03-01  175184.0    3130.0   19380.0 -186036.0   36056.0  -33320.0   \n",
       "2 2014-04-01   84613.0  175184.0    3130.0   19380.0 -186036.0   36056.0   \n",
       "3 2014-05-01   93963.0   84613.0  175184.0    3130.0   19380.0 -186036.0   \n",
       "4 2014-06-01   23965.0   93963.0   84613.0  175184.0    3130.0   19380.0   \n",
       "\n",
       "      lag_6    lag_7    lag_8    lag_9   lag_10    lag_11    lag_12  \n",
       "0  -89161.0  60325.0  32355.0  80968.0  64892.0  157965.0    4513.0  \n",
       "1  -76854.0 -89161.0  60325.0  32355.0  80968.0   64892.0  157965.0  \n",
       "2  -33320.0 -76854.0 -89161.0  60325.0  32355.0   80968.0   64892.0  \n",
       "3   36056.0 -33320.0 -76854.0 -89161.0  60325.0   32355.0   80968.0  \n",
       "4 -186036.0  36056.0 -33320.0 -76854.0 -89161.0   60325.0   32355.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supervised[['date','diff','lag_1','lag_2','lag_3','lag_4','lag_5','lag_6','lag_7','lag_8','lag_9','lag_10','lag_11','lag_12']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795722233296558\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the regression formula\n",
    "model = smf.ols(formula='diff ~ lag_1 + lag_2 + lag_3 + lag_4 + lag_5 + lag_6 + lag_7 + lag_8 + lag_9 + lag_10 + lag_11 + lag_12', data=df_supervised)\n",
    "\n",
    "# Fit the regression\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = model_fit.rsquared_adj\n",
    "print(regression_adj_rsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is impressive as the score is 98%. Now we can confidently build our model after scaling our data. But there is one more step before scaling. We should split our data into train and test sets. As the test set, we have selected the last 6 months’ sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supervised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   diff    47 non-null     float64\n",
      " 1   lag_1   47 non-null     float64\n",
      " 2   lag_2   47 non-null     float64\n",
      " 3   lag_3   47 non-null     float64\n",
      " 4   lag_4   47 non-null     float64\n",
      " 5   lag_5   47 non-null     float64\n",
      " 6   lag_6   47 non-null     float64\n",
      " 7   lag_7   47 non-null     float64\n",
      " 8   lag_8   47 non-null     float64\n",
      " 9   lag_9   47 non-null     float64\n",
      " 10  lag_10  47 non-null     float64\n",
      " 11  lag_11  47 non-null     float64\n",
      " 12  lag_12  47 non-null     float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 4.9 KB\n"
     ]
    }
   ],
   "source": [
    "#import MinMaxScaler and create a new dataframe for LSTM model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_model = df_supervised.drop(['sales','date'],axis=1)\n",
    "\n",
    "#split train and test set\n",
    "train_set, test_set = df_model[0:-6].values, df_model[-6:].values\n",
    "\n",
    "df_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train  (41, 13)\n"
     ]
    }
   ],
   "source": [
    "print(' train ',train_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply Min Max Scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(train_set)\n",
    "\n",
    "# reshape training set\n",
    "train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])\n",
    "\n",
    "train_set_scaled = scaler.transform(train_set)\n",
    "\n",
    "# reshape test set\n",
    "test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])\n",
    "test_set_scaled = scaler.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train shape  (41, 13)  test shape  (6, 13)\n"
     ]
    }
   ],
   "source": [
    "print(' train shape ',train_set_scaled.shape, ' test shape ', test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "\n",
    "X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.15255919, -0.80434393,  0.23024212, -0.0447346 ,\n",
       "         -0.25830878, -0.3186859 ,  0.40696724,  0.26794062,\n",
       "          0.50957454,  0.42966779,  0.8922929 ,  0.12955024]],\n",
       "\n",
       "       [[ 0.07686073,  0.15255919, -0.80434393,  0.29561828,\n",
       "         -0.0447346 , -0.25830878, -0.33606217,  0.40696724,\n",
       "          0.26794062,  0.50957454,  0.42966779,  0.8922929 ]],\n",
       "\n",
       "       [[ 0.8783514 ,  0.07686073,  0.15255919, -0.79394659,\n",
       "          0.29561828, -0.0447346 , -0.27488947, -0.33606217,\n",
       "          0.40696724,  0.26794062,  0.50957454,  0.42966779]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the LSTM model   \n",
    "Everything is ready to build our first deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tridoan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/tridoan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tridoan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.4305\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 879us/step - loss: 0.3638\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 863us/step - loss: 0.3158\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 826us/step - loss: 0.2754\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 848us/step - loss: 0.2406\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 841us/step - loss: 0.2102\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 869us/step - loss: 0.1834\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 888us/step - loss: 0.1595\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 853us/step - loss: 0.1383\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 874us/step - loss: 0.1196\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 866us/step - loss: 0.1033\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 879us/step - loss: 0.0894\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 888us/step - loss: 0.0776\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 873us/step - loss: 0.0676\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 850us/step - loss: 0.0591\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 888us/step - loss: 0.0519\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 909us/step - loss: 0.0458\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 977us/step - loss: 0.0405\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 944us/step - loss: 0.0360\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.0321\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.0288\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.0259\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.0234\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 845us/step - loss: 0.0212\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 849us/step - loss: 0.0194\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 900us/step - loss: 0.0177\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 865us/step - loss: 0.0163\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 869us/step - loss: 0.0151\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 873us/step - loss: 0.0140\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 860us/step - loss: 0.0130\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 888us/step - loss: 0.0121\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 861us/step - loss: 0.0113\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 860us/step - loss: 0.0106\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 898us/step - loss: 0.0100\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 872us/step - loss: 0.0094\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 837us/step - loss: 0.0089\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 836us/step - loss: 0.0084\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 844us/step - loss: 0.0080\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 873us/step - loss: 0.0076\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 883us/step - loss: 0.0072\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 884us/step - loss: 0.0069\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 876us/step - loss: 0.0065\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 921us/step - loss: 0.0063\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 865us/step - loss: 0.0060\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 882us/step - loss: 0.0058\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 855us/step - loss: 0.0055\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 851us/step - loss: 0.0053\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 843us/step - loss: 0.0052\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 894us/step - loss: 0.0050\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 851us/step - loss: 0.0049\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 853us/step - loss: 0.0047\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 865us/step - loss: 0.0046\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 854us/step - loss: 0.0045\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 917us/step - loss: 0.0044\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 861us/step - loss: 0.0043\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 855us/step - loss: 0.0042\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 843us/step - loss: 0.0042\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 859us/step - loss: 0.0041\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 860us/step - loss: 0.0041\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 857us/step - loss: 0.0040\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 851us/step - loss: 0.0039\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 845us/step - loss: 0.0039\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 891us/step - loss: 0.0039\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 898us/step - loss: 0.0038\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 884us/step - loss: 0.0038\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 971us/step - loss: 0.0038\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 890us/step - loss: 0.0037\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 864us/step - loss: 0.0037\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 848us/step - loss: 0.0037\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 851us/step - loss: 0.0036\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 842us/step - loss: 0.0036\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 851us/step - loss: 0.0036\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 858us/step - loss: 0.0036\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 838us/step - loss: 0.0036\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 868us/step - loss: 0.0035\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 888us/step - loss: 0.0035\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 855us/step - loss: 0.0035\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 881us/step - loss: 0.0035\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 911us/step - loss: 0.0035\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 905us/step - loss: 0.0034\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 903us/step - loss: 0.0034\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 934us/step - loss: 0.0034\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 901us/step - loss: 0.0034\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 908us/step - loss: 0.0034\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 896us/step - loss: 0.0033\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 889us/step - loss: 0.0033\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 896us/step - loss: 0.0033\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.0033\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 877us/step - loss: 0.0033\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 881us/step - loss: 0.0033\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 949us/step - loss: 0.0033\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 978us/step - loss: 0.0032\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 900us/step - loss: 0.0032\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 883us/step - loss: 0.0032\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 877us/step - loss: 0.0032\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 885us/step - loss: 0.0032\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 870us/step - loss: 0.0032\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 880us/step - loss: 0.0031\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 873us/step - loss: 0.0031\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 876us/step - loss: 0.0031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a37aa0b50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(4, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, nb_epoch=100, batch_size=1, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let do prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66558945],\n",
       "       [-0.5835324 ],\n",
       "       [-0.39540625],\n",
       "       [-0.03602177],\n",
       "       [ 0.19803987],\n",
       "       [-1.0476856 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test,batch_size=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hese are scaled data that shows the difference. How we can see the actual sales prediction?   \n",
    "First, we need to do the **inverse transformation for scaling**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.66558945]],\n",
       "\n",
       "       [[-0.5835324 ]],\n",
       "\n",
       "       [[-0.39540625]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape y_pred\n",
    "y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])\n",
    "\n",
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66558945  0.26695937  0.44344626  0.60355899  1.10628178  0.13866328\n",
      "  -0.10745675 -1.02635392  0.24535439 -0.05787474 -0.31370458 -0.67437352\n",
      "   0.68397168]]\n",
      "[[-0.58353239  0.55964922  0.26695937  0.44344626  0.68877355  1.10628178\n",
      "   0.13866328 -0.12204966 -1.02635392  0.24535439 -0.05787474 -0.31370458\n",
      "  -0.67437352]]\n",
      "[[-0.39540625 -0.61313659  0.55964922  0.26695937  0.52015228  0.68877355\n",
      "   1.10628178  0.12731349 -0.12204966 -1.02635392  0.24535439 -0.05787474\n",
      "  -0.31370458]]\n",
      "[[-0.03602177 -0.36228353 -0.61313659  0.55964922  0.33428672  0.52015228\n",
      "   0.68877355  1.10768225  0.12731349 -0.12204966 -1.02635392  0.24535439\n",
      "  -0.05787474]]\n",
      "[[ 0.19803987 -0.14316792 -0.36228353 -0.61313659  0.64253037  0.33428672\n",
      "   0.52015228  0.68467253  1.10768225  0.12731349 -0.12204966 -1.02635392\n",
      "   0.24535439]]\n",
      "[[-1.04768562  0.23779333 -0.14316792 -0.36228353 -0.59257833  0.64253037\n",
      "   0.33428672  0.51382935  0.68467253  1.10768225  0.12731349 -0.12204966\n",
      "  -1.02635392]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.66558945,  0.26695937,  0.44344626,  0.60355899,  1.10628178,\n",
       "         0.13866328, -0.10745675, -1.02635392,  0.24535439, -0.05787474,\n",
       "        -0.31370458, -0.67437352,  0.68397168]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rebuild test set for inverse transform\n",
    "pred_test_set = []\n",
    "\n",
    "for index in range(0,len(y_pred)):\n",
    "    print(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
    "    pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
    "\n",
    "pred_test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1, 13)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape pred_test_set\n",
    "pred_test_set = np.array(pred_test_set)\n",
    "pred_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])\n",
    "\n",
    "#inverse transform\n",
    "pred_test_set_inverted = scaler.inverse_transform(pred_test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe that shows the predicted sales\n",
    "result_list = []\n",
    "sales_dates = list(df_sales[-7:].date)\n",
    "act_sales = list(df_sales[-7:].sales)\n",
    "for index in range(0,len(pred_test_set_inverted)):\n",
    "    result_dict = {}\n",
    "    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])\n",
    "    result_dict['date'] = sales_dates[index+1]\n",
    "    result_list.append(result_dict)\n",
    "df_result = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_value</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1194134</td>\n",
       "      <td>2017-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1032758</td>\n",
       "      <td>2017-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928152</td>\n",
       "      <td>2017-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>914160</td>\n",
       "      <td>2017-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>920303</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_value       date\n",
       "0     1194134 2017-07-01\n",
       "1     1032758 2017-08-01\n",
       "2      928152 2017-09-01\n",
       "3      914160 2017-10-01\n",
       "4      920303 2017-11-01"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>454904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>459417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>617382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>682274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>763242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   sales\n",
       "0 2013-01-01  454904\n",
       "1 2013-02-01  459417\n",
       "2 2013-03-01  617382\n",
       "3 2013-04-01  682274\n",
       "4 2013-05-01  763242"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>pred_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>454904</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>459417</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>617382</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>682274</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>763242</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>795597</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>855922</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-08-01</td>\n",
       "      <td>766761</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>689907</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>656587</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>692643</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>506607</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>525987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>529117</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>704301</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>788914</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>882877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>906842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>989010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>885596</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>785124</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>758883</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>800783</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>578048</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>552513</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>551317</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>730951</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>824467</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>926902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>937184</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1037350</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>920401</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>823332</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>797253</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>827645</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>607572</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>602439</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>614957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>790881</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>901950</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>988730</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>1022664</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>1138718</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>981494</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>896831</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>863637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>891448</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>663411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>617306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>621369</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>822667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>938862</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>1020686</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>1064624</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>1171393</td>\n",
       "      <td>1194134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1026403</td>\n",
       "      <td>1032758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>935263</td>\n",
       "      <td>928152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>891160</td>\n",
       "      <td>914160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>928837</td>\n",
       "      <td>920303.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>695170</td>\n",
       "      <td>690563.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    sales  pred_value\n",
       "0  2013-01-01   454904         NaN\n",
       "1  2013-02-01   459417         NaN\n",
       "2  2013-03-01   617382         NaN\n",
       "3  2013-04-01   682274         NaN\n",
       "4  2013-05-01   763242         NaN\n",
       "5  2013-06-01   795597         NaN\n",
       "6  2013-07-01   855922         NaN\n",
       "7  2013-08-01   766761         NaN\n",
       "8  2013-09-01   689907         NaN\n",
       "9  2013-10-01   656587         NaN\n",
       "10 2013-11-01   692643         NaN\n",
       "11 2013-12-01   506607         NaN\n",
       "12 2014-01-01   525987         NaN\n",
       "13 2014-02-01   529117         NaN\n",
       "14 2014-03-01   704301         NaN\n",
       "15 2014-04-01   788914         NaN\n",
       "16 2014-05-01   882877         NaN\n",
       "17 2014-06-01   906842         NaN\n",
       "18 2014-07-01   989010         NaN\n",
       "19 2014-08-01   885596         NaN\n",
       "20 2014-09-01   785124         NaN\n",
       "21 2014-10-01   758883         NaN\n",
       "22 2014-11-01   800783         NaN\n",
       "23 2014-12-01   578048         NaN\n",
       "24 2015-01-01   552513         NaN\n",
       "25 2015-02-01   551317         NaN\n",
       "26 2015-03-01   730951         NaN\n",
       "27 2015-04-01   824467         NaN\n",
       "28 2015-05-01   926902         NaN\n",
       "29 2015-06-01   937184         NaN\n",
       "30 2015-07-01  1037350         NaN\n",
       "31 2015-08-01   920401         NaN\n",
       "32 2015-09-01   823332         NaN\n",
       "33 2015-10-01   797253         NaN\n",
       "34 2015-11-01   827645         NaN\n",
       "35 2015-12-01   607572         NaN\n",
       "36 2016-01-01   602439         NaN\n",
       "37 2016-02-01   614957         NaN\n",
       "38 2016-03-01   790881         NaN\n",
       "39 2016-04-01   901950         NaN\n",
       "40 2016-05-01   988730         NaN\n",
       "41 2016-06-01  1022664         NaN\n",
       "42 2016-07-01  1138718         NaN\n",
       "43 2016-08-01   981494         NaN\n",
       "44 2016-09-01   896831         NaN\n",
       "45 2016-10-01   863637         NaN\n",
       "46 2016-11-01   891448         NaN\n",
       "47 2016-12-01   663411         NaN\n",
       "48 2017-01-01   617306         NaN\n",
       "49 2017-02-01   621369         NaN\n",
       "50 2017-03-01   822667         NaN\n",
       "51 2017-04-01   938862         NaN\n",
       "52 2017-05-01  1020686         NaN\n",
       "53 2017-06-01  1064624         NaN\n",
       "54 2017-07-01  1171393   1194134.0\n",
       "55 2017-08-01  1026403   1032758.0\n",
       "56 2017-09-01   935263    928152.0\n",
       "57 2017-10-01   891160    914160.0\n",
       "58 2017-11-01   928837    920303.0\n",
       "59 2017-12-01   695170    690563.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge with actual sales dataframe\n",
    "df_sales_pred = pd.merge(df_sales,df_result,on='date',how='left')\n",
    "\n",
    "df_sales_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
